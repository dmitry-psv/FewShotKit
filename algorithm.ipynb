{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Manually set the path for the src directory\n",
    "src_path = os.path.abspath('src')\n",
    "sys.path.append(src_path)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Datasets loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I - load \"seed\" dataset from local folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input parameters:\n",
    "# - seed_filename: Name of the file containing the SEED data (located in the raw_data folder).\n",
    "# - x_label: Name of the column containing the input text (dialogue).\n",
    "# - y_label: Name of the column containing the output text (summary).\n",
    "\n",
    "seed_filename = 'data/seed_sampled_100.parquet'\n",
    "x_label = 'dialogue'\n",
    "y_label = 'summary'\n",
    "\n",
    "seed = utils.read_seed(seed_filename,x_label,y_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II - load \"unlabeled\" dataset from local folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input parameters:\n",
    "# - unlabeled_filename: Name of the file containing the UNLABELED data (located in the raw_data folder).\n",
    "# - x_label: Name of the column containing the input text (dialogue).\n",
    "\n",
    "unlabeled_filename = 'data/unlabeled_sampled_1000.parquet'\n",
    "x_label = 'dialogue'\n",
    "\n",
    "unlabeled = utils.read_unlabeled(unlabeled_filename, x_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2 - Text preprocessing module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I - \"seed\" dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_list = [\n",
    "            remove_html_tags,\n",
    "            remove_url, \n",
    "            chat_conversion, \n",
    "            remove_stopwords, \n",
    "            spelling_correction, \n",
    "            rewrite_emoji\n",
    "            ]\n",
    "\n",
    "# Apply the defined preprocessing functions to the 'seed' dataset\n",
    "# 'seed' is the DataFrame to be processed\n",
    "# 'x_label' specifies the column in 'seed' that contains the text to be preprocessed\n",
    "# func_list is the list of preprocessing functions to apply\n",
    "seed = process_dataset(seed, 'x_label', func_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II - \"unlabeled\" dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the defined preprocessing functions to the 'unlabeled' dataset\n",
    "unlabeled = process_dataset(unlabeled, 'x_label', func_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "III - Save to folder (a new folder is created, and both files are saved into it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to cache/2025-03-23_13:38:20\n"
     ]
    }
   ],
   "source": [
    "utils.save_to_folder(seed, unlabeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3 - Embedding Generation Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I - Load the preprocessed dataset from the data folder: \"seed\" and \"unlabeled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = '2025-03-23_13:38:20'\n",
    "\n",
    "seed, unlabeled = utils.read_from_folder(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: CUDA requested but not available. Using CPU instead.\n",
      "Warning: Using CPU for computations. This might be slow for large datasets.\n",
      "Loading tokenizer and model from BAAI/bge-small-en-v1.5\n",
      "Trust remote code: True\n",
      "Model embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "from embeddings import EmbeddingGenerator\n",
    "\n",
    "model = 'BAAI/bge-small-en-v1.5'\n",
    "device = 'cuda'\n",
    "\n",
    "embedding_generator = EmbeddingGenerator(\n",
    "            model_name=model,\n",
    "            device=device,\n",
    "            trust_remote_code=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II - Check if the loaded data already contains embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenization statistics (from first 100 texts):\n",
      "Average length: 103.5 tokens\n",
      "Maximum length: 360 tokens\n",
      "Texts will be truncated to 512 tokens if longer\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding texts: 100%|██████████| 100/100 [00:03<00:00, 27.99batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final embedding shape: (100, 384) (100 samples, 384 dimensions)\n",
      "Embeddings saved to ../embeddings/batch_bge-small-en-v1.5_20250323_133938.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if 'embedding' not in seed.columns:\n",
    "    seed_embeddings = embedding_generator.encode_batch(\n",
    "            texts=seed['x_label'].tolist(),\n",
    "            batch_size=1,\n",
    "            max_length=512\n",
    "        )\n",
    "    seed['embedding'] = list(seed_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenization statistics (from first 100 texts):\n",
      "Average length: 103.5 tokens\n",
      "Maximum length: 360 tokens\n",
      "Texts will be truncated to 512 tokens if longer\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding texts: 100%|██████████| 1000/1000 [00:37<00:00, 27.00batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final embedding shape: (1000, 384) (1000 samples, 384 dimensions)\n",
      "Embeddings saved to ../embeddings/batch_bge-small-en-v1.5_20250323_134020.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if 'embedding' not in unlabeled.columns:\n",
    "    unlabeled_embeddings = embedding_generator.encode_batch(\n",
    "            texts=unlabeled['x_label'].tolist(),\n",
    "            batch_size=1,\n",
    "            max_length=512\n",
    "        )\n",
    "    unlabeled['embedding'] = list(unlabeled_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "III - Save 'seed' and 'unlabeled' to the same folder from which the original data was loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to cache/2025-03-23_13:38:20\n"
     ]
    }
   ],
   "source": [
    "utils.save_to_folder(seed, unlabeled, folder_name = folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 4 - Iteration cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I - Connect to the (remote) database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'collection_2' does not exist, creating...\n",
      "Collection 'collection_2' created!\n"
     ]
    }
   ],
   "source": [
    "# Option with remote server\n",
    "import database\n",
    "collection_name = 'collection_2'\n",
    "metric_type = 'IP'\n",
    "\n",
    "# Initialize VectorDatabase\n",
    "vector_db = database.VectorDatabase(\n",
    "    uri=os.getenv('MILVUS_URI'),\n",
    "    token=os.getenv('MILVUS_TOKEN'),\n",
    "    collection_name=collection_name,\n",
    "    embedding_dim=len(seed['embedding'].iloc[0]),\n",
    "    metric_type=metric_type\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II - Import 'seed' data into the database (if not already done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting seed data...(100 entities left) \n",
      "Inserting 100 records into collection: collection_2\n",
      "Total insert time: 0 seconds\n",
      "Flushing collection...\n"
     ]
    }
   ],
   "source": [
    "# Get all data from collection\n",
    "data_from_collection = vector_db.get_collection_data(['embedding'])\n",
    "\n",
    "# Convert embeddings in both dataframes to lists for comparison\n",
    "seed_embeddings = [embedding.tolist() for embedding in seed['embedding']]\n",
    "data_from_collection_embeddings = data_from_collection['embedding'].tolist() if data_from_collection.empty != True else []\n",
    "\n",
    "# Filter seed dataframe to exclude rows where the 'embedding' is in data_from_collection\n",
    "seed_filtered = seed[~seed['embedding'].apply(lambda x: x.tolist()).isin(data_from_collection_embeddings)]\n",
    "\n",
    "if seed_filtered.empty != True:\n",
    "    print(f'Inserting seed data...({len(seed_filtered)} entities left) ')\n",
    "    vector_db.bulk_upsert(\n",
    "        input_texts  = seed_filtered['x_label'].tolist(),\n",
    "        embeddings   = seed_filtered['embedding'].tolist(),\n",
    "        output_texts = seed_filtered['y_label'].tolist(),\n",
    "        batch_size   = 100\n",
    "    )\n",
    "else:\n",
    "    print('Collection already has data. Skipping seed data insertion...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "III - Get the current 'unlabeled' set in case some of its data has already been processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "892 entities left \n"
     ]
    }
   ],
   "source": [
    "# Get all data from collection\n",
    "data_from_collection = vector_db.get_collection_data(['embedding'])\n",
    "\n",
    "unlabeled_embeddings = [embedding.tolist() for embedding in unlabeled['embedding']]\n",
    "data_from_collection_embeddings = data_from_collection['embedding'].tolist() if data_from_collection.empty != True else []\n",
    "\n",
    "# Filter unlabeled dataframe to exclude rows where the 'embedding' is in data_from_collection\n",
    "unlabeled_filtered = unlabeled[~unlabeled['embedding'].apply(lambda x: x.tolist()).isin(data_from_collection_embeddings)]\n",
    "\n",
    "print(f'{len(unlabeled_filtered)} entities left ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IV - Start main cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import llminteraction\n",
    "from tqdm import tqdm\n",
    "\n",
    "for index, row in tqdm(unlabeled_filtered.iterrows(), total=len(unlabeled_filtered)):\n",
    "\n",
    "    # Get the nearest top_k neighbors\n",
    "    neighbors = vector_db.search_engine(\n",
    "        query_embedding=row['embedding'],\n",
    "        top_k=2\n",
    "    )\n",
    "    \n",
    "    # Build a prompt\n",
    "    prompt = llminteraction.build_icl_prompt(\n",
    "        examples=neighbors,\n",
    "        new_dialogue = row['x_label'],\n",
    "    )\n",
    "\n",
    "    # LLM interaction\n",
    "    response = llminteraction.call_openrouter_llm(\n",
    "        prompt=prompt,\n",
    "        model=\"google/gemma-3-27b-it\",\n",
    "        openrouter_api_key=os.getenv('OPENROUTER_API_KEY'),\n",
    "        temperature=0.3\n",
    "    )   \n",
    "    \n",
    "    # Update the database\n",
    "    vector_db.upsert(\n",
    "        input_text=row['x_label'],\n",
    "        embedding=row['embedding'],\n",
    "        output_text=response\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
